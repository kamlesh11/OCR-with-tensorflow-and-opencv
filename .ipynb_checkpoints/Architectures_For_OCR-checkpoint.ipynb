{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXs4cfky9vVD"
   },
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6dI3LC669p2x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 12:58:59.174073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-11 12:58:59.174110: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class ResNet:\n",
    "\t@staticmethod\n",
    "\tdef residual_module(data, K, stride, chanDim, red=False,\n",
    "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "\t\t# the shortcut branch of the ResNet module should be\n",
    "\t\t# initialize as the input (identity) data\n",
    "\t\tshortcut = data\n",
    "\n",
    "\t\t# the first block of the ResNet module are the 1x1 CONVs\n",
    "\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(data)\n",
    "\t\tact1 = Activation(\"relu\")(bn1)\n",
    "\t\tconv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "\t\t# the second block of the ResNet module are the 3x3 CONVs\n",
    "\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(conv1)\n",
    "\t\tact2 = Activation(\"relu\")(bn2)\n",
    "\t\tconv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n",
    "\t\t\tpadding=\"same\", use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act2)\n",
    "\n",
    "\t\t# the third block of the ResNet module is another set of 1x1\n",
    "\t\t# CONVs\n",
    "\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(conv2)\n",
    "\t\tact3 = Activation(\"relu\")(bn3)\n",
    "\t\tconv3 = Conv2D(K, (1, 1), use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act3)\n",
    "\n",
    "\t\t# if we are to reduce the spatial size, apply a CONV layer to\n",
    "\t\t# the shortcut\n",
    "\t\tif red:\n",
    "\t\t\tshortcut = Conv2D(K, (1, 1), strides=stride,\n",
    "\t\t\t\tuse_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "\t\t# add together the shortcut and the final CONV\n",
    "\t\tx = add([conv3, shortcut])\n",
    "\n",
    "\t\t# return the addition as the output of the ResNet module\n",
    "\t\treturn x\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes, stages, filters,\n",
    "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9, dataset=\"cifar\"):\n",
    "\t\t# initialize the input shape to be \"channels last\" and the\n",
    "\t\t# channels dimension itself\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "\n",
    "\t\t# set the input and apply BN\n",
    "\t\tinputs = Input(shape=inputShape)\n",
    "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(inputs)\n",
    "\n",
    "\t\t# check if we are utilizing the CIFAR dataset\n",
    "\t\tif dataset == \"cifar\":\n",
    "\t\t\t# apply a single CONV layer\n",
    "\t\t\tx = Conv2D(filters[0], (3, 3), use_bias=False,\n",
    "\t\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "\n",
    "\t\t# check to see if we are using the Tiny ImageNet dataset\n",
    "\t\telif dataset == \"tiny_imagenet\":\n",
    "\t\t\t# apply CONV => BN => ACT => POOL to reduce spatial size\n",
    "\t\t\tx = Conv2D(filters[0], (5, 5), use_bias=False,\n",
    "\t\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "\t\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\t\tmomentum=bnMom)(x)\n",
    "\t\t\tx = Activation(\"relu\")(x)\n",
    "\t\t\tx = ZeroPadding2D((1, 1))(x)\n",
    "\t\t\tx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "\t\t# loop over the number of stages\n",
    "\t\tfor i in range(0, len(stages)):\n",
    "\t\t\t# initialize the stride, then apply a residual module\n",
    "\t\t\t# used to reduce the spatial size of the input volume\n",
    "\t\t\tstride = (1, 1) if i == 0 else (2, 2)\n",
    "\t\t\tx = ResNet.residual_module(x, filters[i + 1], stride,\n",
    "\t\t\t\tchanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "\t\t\t# loop over the number of layers in the stage\n",
    "\t\t\tfor j in range(0, stages[i] - 1):\n",
    "\t\t\t\t# apply a ResNet module\n",
    "\t\t\t\tx = ResNet.residual_module(x, filters[i + 1],\n",
    "\t\t\t\t\t(1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "\t\t# apply BN => ACT => POOL\n",
    "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(x)\n",
    "\t\tx = Activation(\"relu\")(x)\n",
    "\t\tx = AveragePooling2D((8, 8))(x)\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tx = Flatten()(x)\n",
    "\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "\t\tx = Activation(\"softmax\")(x)\n",
    "\n",
    "\t\t# create the model\n",
    "\t\tmodel = Model(inputs, x, name=\"resnet\")\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szrOZuD292g6"
   },
   "source": [
    "## RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3655,
     "status": "ok",
     "timestamp": 1625460075937,
     "user": {
      "displayName": "Kamlesh Solanki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhA0MEP-zpMOhAfgWjxkBenJosW6gMJNXVKGLhPQ=s64",
      "userId": "01932726589432915100"
     },
     "user_tz": -330
    },
    "id": "ltquXLvq9_LP"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, Reshape,MaxPool2D,Dense\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Lambda\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "#from configuration import window_height, window_width, MPoolLayers_ALL, LastFilters, NUnits\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "88hhdKSq-DnU"
   },
   "outputs": [],
   "source": [
    "\n",
    "#General configurations\n",
    "window_height = 64  #windown height\n",
    "window_width = 64   #window width\n",
    "window_shift = window_width - 2 #window shift\n",
    "\n",
    "#CNN related configurations\n",
    "MPoolLayers_ALL = 5\t#Nbr of all maxpool layers\n",
    "MPoolLayers_H = 2\t#Nbr of maxpool in horizontal dimension\n",
    "LastFilters = 512\t#Nbr of feature maps at the last conv layer\n",
    "\n",
    "#LSTM related configurations\n",
    "NUnits = 256    #Number of units in forward/backward LSTM\n",
    "NLayers = 3     #Number of layers in BLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "i7OFoFpB-GVx"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "FV = int(window_height / math.pow(2, MPoolLayers_ALL))\n",
    "NFeatures = FV * LastFilters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "67CQVHcZ-Ig6"
   },
   "outputs": [],
   "source": [
    "char_list = string.ascii_letters+string.digits\n",
    "l=\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eSYzYj4q-NWS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 12:59:14.830350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-11 12:59:14.830389: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-11 12:59:14.830412: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nb-1061): /proc/driver/nvidia/version does not exist\n",
      "2021-10-11 12:59:14.830730: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%%\n",
    "input_data = Input(shape=(window_height, window_width, 1))\n",
    "\n",
    "convolution1 = Conv2D(filters=64, kernel_size=(1,1))(input_data)\n",
    "convolution1 = BatchNormalization(axis = -1)(convolution1)\n",
    "convolution1 = Activation(\"relu\")(convolution1)\n",
    "\n",
    "convolution2 = Conv2D(filters=64, kernel_size=(1,1))(convolution1)\n",
    "convolution2 = BatchNormalization(axis = -1)(convolution2)\n",
    "convolution2 = Activation(\"relu\")(convolution2)\n",
    "\n",
    "pooling1 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(convolution2)\n",
    "\n",
    "convolution3 = Conv2D(filters=128, kernel_size=(1,1))(pooling1)\n",
    "convolution3 = BatchNormalization(axis = -1)(convolution3)\n",
    "convolution3 = Activation(\"relu\")(convolution3)\n",
    "\n",
    "convolution4 = Conv2D(filters=128, kernel_size=(1,1))(convolution3)\n",
    "convolution4 = BatchNormalization(axis = -1)(convolution4)\n",
    "convolution4 = Activation(\"relu\")(convolution4)\n",
    "\n",
    "pooling2 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(convolution4)\n",
    "\n",
    "convolution5 = Conv2D(filters=256, kernel_size=(1,1))(pooling2)\n",
    "convolution5 = BatchNormalization(axis = -1)(convolution5)\n",
    "convolution5 = Activation(\"relu\")(convolution5)\n",
    "\n",
    "convolution6 = Conv2D(filters=256, kernel_size=(1,1))(convolution5)\n",
    "convolution6 = BatchNormalization(axis = -1)(convolution6)\n",
    "convolution6 = Activation(\"relu\")(convolution6)\n",
    "\n",
    "convolution7 = Conv2D(filters=256, kernel_size=(1,1))(convolution6)\n",
    "convolution7 = BatchNormalization(axis = -1)(convolution7)\n",
    "convolution7 = Activation(\"relu\")(convolution7)\n",
    "\n",
    "pooling3 = MaxPooling2D(pool_size=(2,1), strides=(2,1))(convolution7)\n",
    "\n",
    "convolution8 = Conv2D(filters=512, kernel_size=(1,1))(pooling3)\n",
    "convolution8 = BatchNormalization(axis = -1)(convolution8)\n",
    "convolution8 = Activation(\"relu\")(convolution8)\n",
    "\n",
    "convolution9 = Conv2D(filters=512, kernel_size=(1,1))(convolution8)\n",
    "convolution9 = BatchNormalization(axis = -1)(convolution9)\n",
    "convolution9 = Activation(\"relu\")(convolution9)\n",
    "\n",
    "convolution10 = Conv2D(filters=512, kernel_size=(1,1))(convolution9)\n",
    "convolution10= BatchNormalization(axis = -1)(convolution10)\n",
    "convolution10 = Activation(\"relu\")(convolution10)\n",
    "\n",
    "pooling4 = MaxPooling2D(pool_size=(2,1), strides=(2,1))(convolution10)\n",
    "\n",
    "convolution11 = Conv2D(filters=512, kernel_size=(1,1))(pooling4)\n",
    "convolution11= BatchNormalization(axis = -1)(convolution11)\n",
    "convolution11 = Activation(\"relu\")(convolution11)\n",
    "\n",
    "convolution12 = Conv2D(filters=512, kernel_size=(1,1))(convolution11)\n",
    "convolution12= BatchNormalization(axis = -1)(convolution12)\n",
    "convolution12 = Activation(\"relu\")(convolution12)\n",
    "\n",
    "convolution13 = Conv2D(filters=512, kernel_size=(1,1))(convolution12)\n",
    "convolution13= BatchNormalization(axis = -1)(convolution13)\n",
    "convolution13 = Activation(\"relu\")(convolution13)\n",
    "\n",
    "pooling5 = MaxPooling2D(pool_size=(2,1), strides=(2,1))(convolution13)\n",
    "\n",
    "convolution_full = Reshape(target_shape=(LastFilters * FV, 16))(pooling5)\n",
    "\n",
    "bidir_LSTM1 = Bidirectional(LSTM(units = NUnits, return_sequences=True))(convolution_full)\n",
    "bidir_LSTM2 = Bidirectional(LSTM(units = NUnits, return_sequences=True))(bidir_LSTM1)\n",
    "#y_pred = Bidirectional(LSTM(units = NUnits))(bidir_LSTM2)\n",
    "outputs = Dense(len(char_list)+1, activation = 'softmax')(bidir_LSTM2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-1EvAMw-XXu"
   },
   "source": [
    "## RCNN - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4nlOtkUd-POt"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32,32,1))\n",
    "\n",
    "# convolution layer with kernel size (3,3)\n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "# poolig layer with kernel size (2,2)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    "\n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "# poolig layer with kernel size (2,1)\n",
    "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "# Batch normalization layer\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    "\n",
    "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
    "\n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    "\n",
    "# bidirectional LSTM layers with units=128\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    "\n",
    "outputs = Dense(len(l)+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "act_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WqFvMfiR-fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 1, 7, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 7, 256)            656384    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 7, 256)            394240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7, 63)             16191     \n",
      "=================================================================\n",
      "Total params: 6,619,711\n",
      "Trainable params: 6,617,663\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMU0R9gnM3t76yObJYQZLB6",
   "name": "Architectures_For_OCR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
